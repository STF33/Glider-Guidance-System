{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sal_f\\anaconda3\\envs\\env_ggs0\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "\n",
    "from X_functions import *\n",
    "from X_config import *\n",
    "from X_models import *\n",
    "from X_interpolation import *\n",
    "from X_products import *\n",
    "\n",
    "from GGS_main import *\n",
    "\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GGS Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "power=1\n",
    "path=\"local\"\n",
    "config_name=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### IMPORTING GGS CONFIGURATION: test ###\n",
      "\n",
      "Configuration import success!\n",
      "\n",
      "### PROCESSING GGS CONFIGURATION ###\n",
      "\n",
      "Configuration:\n",
      "\n",
      "--> MISSION\n",
      "mission_name: Sentinel Leg 1\n",
      "target_date: 2024-04-11T20:17:59+0000\n",
      "max_depth: 1000\n",
      "extent: ((10, -78), (44, -10))\n",
      "GPS_coords: [[41.675, -70.522], [40.04, -70.67], [37.875, -70.742], [37.738, -65.998], [39.12, -61.486], [36.026, -60.242], [31.012, -54.977], [31.79, -53.372], [26.176, -45.272], [20.712, -33.73], [15.067, -23.65]]\n",
      "glider_id: None\n",
      "glider_buffer: None\n",
      "\n",
      "--> MODEL\n",
      "single_datetime: True\n",
      "enable_rtofs: False\n",
      "enable_cmems: True\n",
      "enable_gofs: True\n",
      "chunk: True\n",
      "save_model_data: False\n",
      "save_depth_average: True\n",
      "save_bin_average: False\n",
      "\n",
      "--> PRODUCT\n",
      "create_magnitude_plot: False\n",
      "create_threshold_plot: True\n",
      "create_advantage_plot: False\n",
      "create_profile_plot: False\n",
      "create_gpkg_file: False\n",
      "latitude_qc: 39\n",
      "longitude_qc: -69\n",
      "density: 3\n",
      "mag1: 0.0\n",
      "mag2: 0.2\n",
      "mag3: 0.3\n",
      "mag4: 0.4\n",
      "mag5: 0.5\n",
      "tolerance: 15\n",
      "show_gliders: False\n",
      "show_waypoints: True\n",
      "show_eez: True\n",
      "show_qc: False\n",
      "manual_extent: None\n",
      "compute_optimal_path: True\n",
      "\n",
      "--> DATA\n",
      "bathymetry_path: c:\\Users\\sal_f\\OneDrive\\Desktop\\STF-0\\!-GGS\\GGS_Scripts\\data/bathymetry/GEBCO_2023_sub_ice_topo.nc\n",
      "eez_path: c:\\Users\\sal_f\\OneDrive\\Desktop\\STF-0\\!-GGS\\GGS_Scripts\\data/eez/eez_boundaries_v12.shp\n",
      "\n",
      "--> ADVANCED\n",
      "reprocess: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config_name is None:\n",
    "    print(\"No config file specified. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "config = GGS_config_import(config_name)\n",
    "\n",
    "target_datetime = config['MISSION'].get('target_date')\n",
    "if not target_datetime:\n",
    "    print(\"Issue with target datetime. Using current datetime.\")\n",
    "    target_datetime = dt.datetime.now(dt.timezone.utc)\n",
    "\n",
    "if path == \"local\":\n",
    "    root_directory = GGS_config_process(config, path=\"default\")\n",
    "elif path == \"rucool\":\n",
    "    root_directory = GGS_config_process(config, path=\"/www/web/rucool/hurricane/model_comparisons/maps/yucatan\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid root directory.\")\n",
    "\n",
    "datetime_list = [target_datetime.replace(hour=0, minute=0, second=0, microsecond=0).strftime('%Y-%m-%dT%H:%M:%SZ')]\n",
    "datetime_index = datetime_list[0]\n",
    "\n",
    "glider_dataframes = None\n",
    "if config['PRODUCT'].get('show_gliders'):\n",
    "    min_lat, min_lon = config['MISSION']['extent'][0]\n",
    "    max_lat, max_lon = config['MISSION']['extent'][1]\n",
    "    search_extent = [min_lon, max_lon, min_lat, max_lat]\n",
    "    glider_dataframes = acquire_gliders(\n",
    "        extent=search_extent,\n",
    "        target_date=target_datetime,\n",
    "        date_delta=dt.timedelta(days=1),\n",
    "        requested_variables=[\"time\", \"longitude\", \"latitude\", \"profile_id\", \"depth\"],\n",
    "        print_vars=False,\n",
    "        target=\"all\",\n",
    "        request_timeout=5,\n",
    "        enable_parallel=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime 2024-04-11T00:00:00Z unprocessed, proceeding with task.\n"
     ]
    }
   ],
   "source": [
    "datetime_index = datetime_index\n",
    "config_flag = config\n",
    "root_directory_flag = root_directory\n",
    "glider_data_flag = glider_dataframes\n",
    "\n",
    "enable_rtofs_flag = config_flag['MODEL']['enable_rtofs']\n",
    "enable_cmems_flag = config_flag['MODEL']['enable_cmems']\n",
    "enable_gofs_flag = config_flag['MODEL']['enable_gofs']\n",
    "save_model_data_flag = config_flag['MODEL']['save_model_data']\n",
    "save_depth_average_flag = config_flag['MODEL']['save_depth_average']\n",
    "save_bin_average_flag = config_flag['MODEL']['save_bin_average']\n",
    "chunk_flag = config_flag['MODEL']['chunk']\n",
    "\n",
    "create_magnitude_plot_flag = config_flag['PRODUCT']['create_magnitude_plot']\n",
    "create_threshold_plot_flag = config_flag['PRODUCT']['create_threshold_plot']\n",
    "create_advantage_plot_flag = config_flag['PRODUCT']['create_advantage_plot']\n",
    "create_profiles_plot_flag = config_flag['PRODUCT']['create_profile_plot']\n",
    "create_gpkg_file_flag = config_flag['PRODUCT']['create_gpkg_file']\n",
    "latitude_qc_flag = config_flag['PRODUCT']['latitude_qc']\n",
    "longitude_qc_flag = config_flag['PRODUCT']['longitude_qc']\n",
    "density_flag = config_flag['PRODUCT']['density']\n",
    "mag1_flag = config_flag['PRODUCT']['mag1']\n",
    "mag2_flag = config_flag['PRODUCT']['mag2']\n",
    "mag3_flag = config_flag['PRODUCT']['mag3']\n",
    "mag4_flag = config_flag['PRODUCT']['mag4']\n",
    "mag5_flag = config_flag['PRODUCT']['mag5']\n",
    "tolerance_flag = config_flag['PRODUCT']['tolerance']\n",
    "show_waypoints_flag = config_flag['PRODUCT']['show_waypoints']\n",
    "show_eez_flag = config_flag['PRODUCT']['show_eez']\n",
    "show_qc_flag = config_flag['PRODUCT']['show_qc']\n",
    "manual_extent_flag = config_flag['PRODUCT']['manual_extent']\n",
    "compute_optimal_path_flag = config_flag['PRODUCT']['compute_optimal_path']\n",
    "\n",
    "sub_directory_plots = os.path.join(root_directory_flag, \"plots\", ''.join(datetime_index[:10].split('-')))\n",
    "os.makedirs(sub_directory_plots, exist_ok=True)\n",
    "sub_directory_data = os.path.join(root_directory_flag, \"data\", ''.join(datetime_index[:10].split('-')))\n",
    "os.makedirs(sub_directory_data, exist_ok=True)\n",
    "\n",
    "check_datetime = pd.to_datetime(datetime_index).strftime('%Y%m%dT%HZ')\n",
    "check_pattern = os.path.join(sub_directory_data, f\"*_DepthAverageData_{check_datetime}.nc\")\n",
    "check_files = glob.glob(check_pattern)\n",
    "if check_files:\n",
    "    print(f\"Datetime {datetime_index} already processed: {check_files[0]}, skipping task.\")\n",
    "else:\n",
    "    print(f\"Datetime {datetime_index} unprocessed, proceeding with task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datasets = []\n",
    "\n",
    "if config_flag['ADVANCED']['reprocess']:\n",
    "    current_directory = os.getcwd()\n",
    "    reprocess_path = os.path.join(current_directory, \"data/reprocess\")\n",
    "\n",
    "    model_datasets = []\n",
    "    model_files = glob.glob(os.path.join(reprocess_path, '*.nc'))\n",
    "    for model_file in model_files:\n",
    "        depth_average_dataset = xr.open_dataset(model_file)\n",
    "        model_name = depth_average_dataset.attrs['model_name']\n",
    "        if model_name == 'RTOFS':\n",
    "            rtofs_datasets = (None, depth_average_dataset, None)\n",
    "            model_datasets.append(rtofs_datasets)\n",
    "        elif model_name == 'CMEMS':\n",
    "            cmems_datasets = (None, depth_average_dataset, None)\n",
    "            model_datasets.append(cmems_datasets)\n",
    "        elif model_name == 'GOFS':\n",
    "            gofs_datasets = (None, depth_average_dataset, None)\n",
    "            model_datasets.append(gofs_datasets)\n",
    "else:\n",
    "    if enable_rtofs_flag:\n",
    "        try:\n",
    "            rtofs = RTOFS()\n",
    "            rtofs.rtofs_load(config_flag, datetime_index)\n",
    "            rtofs.rtofs_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "            rtofs_model_data = rtofs.data\n",
    "            rtofs_depth_average, rtofs_bin_average = interpolate_rtofs(config_flag, sub_directory_data, rtofs_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "            rtofs_datasets = (rtofs_model_data, rtofs_depth_average, rtofs_bin_average)\n",
    "            model_datasets.append(rtofs_datasets)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during RTOFS processing: {e}\")\n",
    "    if enable_cmems_flag:\n",
    "        try:\n",
    "            cmems = CMEMS(username='sfricano1', password='GlobalGliders1')\n",
    "            cmems.cmems_load(config_flag, datetime_index)\n",
    "            cmems.cmems_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "            cmems_model_data = cmems.data\n",
    "            cmems_depth_average, cmems_bin_average = interpolate_cmems(config_flag, sub_directory_data, cmems_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "            cmems_datasets = (cmems_model_data, cmems_depth_average, cmems_bin_average)\n",
    "            model_datasets.append(cmems_datasets)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during CMEMS processing: {e}\")\n",
    "    if enable_gofs_flag:\n",
    "        try:\n",
    "            gofs = GOFS()\n",
    "            gofs.gofs_load(config_flag, datetime_index)\n",
    "            gofs.gofs_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "            gofs_model_data = gofs.data\n",
    "            gofs_depth_average, gofs_bin_average = interpolate_gofs(config_flag, sub_directory_data, gofs_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "            gofs_datasets = (gofs_model_data, gofs_depth_average, gofs_bin_average)\n",
    "            model_datasets.append(gofs_datasets)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during GOFS processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CREATING THRESHOLD PLOT ###\n",
      "\n",
      "Start time (UTC): 2024-04-11 20:17:59.561396\n",
      "Computing optimal path for the mission.\n",
      "!!!WARNING!!!: This feature is experimental and may not work as expected. Use at your own risk.\n",
      "Direct path used from (41.66667, -70.5) to (40.0, -70.666664).\n",
      "Total mission time (adjusted): [17688631.84835901] seconds\n",
      "Total mission distance: 6098654.257977845 meters\n",
      "End time (UTC): 2024-04-11 20:25:20.823584\n",
      "Run time: 0:07:21.262188\n"
     ]
    }
   ],
   "source": [
    "if create_magnitude_plot_flag:\n",
    "    GGS_plot_magnitude(\n",
    "        config_flag,\n",
    "        sub_directory_plots,\n",
    "        datetime_index,\n",
    "        model_datasets,\n",
    "        latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "        density=density_flag,\n",
    "        gliders=glider_data_flag,\n",
    "        show_waypoints=show_waypoints_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "        manual_extent=manual_extent_flag,\n",
    "        compute_optimal_path=compute_optimal_path_flag\n",
    "    )\n",
    "if create_threshold_plot_flag:\n",
    "    GGS_plot_threshold(\n",
    "        config_flag,\n",
    "        sub_directory_plots,\n",
    "        datetime_index,\n",
    "        model_datasets,\n",
    "        latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "        density=density_flag,\n",
    "        mag1=mag1_flag, mag2=mag2_flag, mag3=mag3_flag, mag4=mag4_flag, mag5=mag5_flag,\n",
    "        gliders=glider_data_flag,\n",
    "        show_waypoints=show_waypoints_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "        manual_extent=manual_extent_flag,\n",
    "        compute_optimal_path=compute_optimal_path_flag\n",
    "    )\n",
    "if create_advantage_plot_flag:\n",
    "    GGS_plot_advantage(\n",
    "        config_flag,\n",
    "        sub_directory_plots,\n",
    "        datetime_index,\n",
    "        model_datasets,\n",
    "        latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "        density=density_flag,\n",
    "        tolerance=tolerance_flag,\n",
    "        mag1=mag1_flag, mag2=mag2_flag, mag3=mag3_flag, mag4=mag4_flag, mag5=mag5_flag,\n",
    "        gliders=glider_data_flag,\n",
    "        show_waypoints=show_waypoints_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "        manual_extent=manual_extent_flag,\n",
    "        compute_optimal_path=compute_optimal_path_flag\n",
    "    )\n",
    "if create_profiles_plot_flag:\n",
    "    GGS_plot_profiles(\n",
    "        config_flag,\n",
    "        sub_directory_plots,\n",
    "        datetime_index,\n",
    "        model_datasets,\n",
    "        latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "        threshold=0.5\n",
    "    )\n",
    "if create_gpkg_file_flag:\n",
    "    GGS_export_gpkg(\n",
    "        sub_directory_data,\n",
    "        datetime_index,\n",
    "        model_datasets\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GGS Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_path(config, model_dataset, glider_raw_speed=0.5):\n",
    "    \n",
    "    '''\n",
    "    Calculates the optimal path between waypoints for a mission, considering the impact of ocean currents and distance.\n",
    "    \n",
    "    This function uses the \"A*\" algorithm to determine the most efficient path between waypoints specified in the config,\n",
    "    taking into account the ocean's depth-averaged current data provided by the \"model_dataset\".\n",
    "\n",
    "    Args:\n",
    "    - config (dict): A dictionary containing mission config details including waypoints.\n",
    "    - model_dataset (xarray.Dataset): An xarray dataset containing depth-averaged ocean current data.\n",
    "    - glider_raw_speed (float, optional): The glider's base speed in meters per second\n",
    "        - default: 0.5\n",
    "\n",
    "    Returns:\n",
    "    - optimal_mission_path (list of tuples): A list of latitude and longitude tuples representing the optimal route.\n",
    "    '''\n",
    "    \n",
    "    print(\"Computing optimal path for the mission.\")\n",
    "    print(\"!!!WARNING!!!: This feature is experimental and may not work as expected. Use at your own risk.\")\n",
    "\n",
    "    def calculate_haversine_distance(longitude1, latitude1, longitude2, latitude2):\n",
    "        '''Calculates the great circle distance between two points on the earth using the Haversine formula.'''\n",
    "        longitude1, latitude1, longitude2, latitude2 = map(radians, [longitude1, latitude1, longitude2, latitude2])\n",
    "        delta_longitude = longitude2 - longitude1\n",
    "        delta_latitude = latitude2 - latitude1\n",
    "        a = sin(delta_latitude / 2)**2 + cos(latitude1) * cos(latitude2) * sin(delta_longitude / 2)**2\n",
    "        distance = 2 * asin(sqrt(a)) * 6371000\n",
    "        return distance\n",
    "    \n",
    "    def calculate_route_analytics(model_dataset, start_index, end_index, glider_raw_speed):\n",
    "        '''Calculates time, distance, and adjusted time between two points considering ocean currents.'''\n",
    "        start_lat, start_lon = convert_grid2coord(*start_index)\n",
    "        end_lat, end_lon = convert_grid2coord(*end_index)\n",
    "        direction = np.arctan2(end_lon - start_lon, end_lat - start_lat)\n",
    "        u_current = model_dataset['u_depth_avg'].isel(lat=start_index[0], lon=start_index[1]).values\n",
    "        v_current = model_dataset['v_depth_avg'].isel(lat=start_index[0], lon=start_index[1]).values\n",
    "        current_speed = u_current * np.cos(direction) + v_current * np.sin(direction)\n",
    "        net_speed = max(glider_raw_speed + current_speed, 0.1)\n",
    "        distance = calculate_haversine_distance(start_lon, start_lat, end_lon, end_lat)\n",
    "        time = distance / net_speed\n",
    "        return time, distance\n",
    "\n",
    "    def calculate_direct_path(start_index, end_index, glider_raw_speed):\n",
    "        '''Fallback to the direct great circle path if no optimal path is found.'''\n",
    "        start_lat, start_lon = convert_grid2coord(*start_index)\n",
    "        end_lat, end_lon = convert_grid2coord(*end_index)\n",
    "        distance = calculate_haversine_distance(start_lon, start_lat, end_lon, end_lat)\n",
    "        time = distance / glider_raw_speed\n",
    "        return [(start_lat, start_lon), (end_lat, end_lon)], time, distance\n",
    "\n",
    "    def convert_coord2grid(latitude, longitude):\n",
    "        '''Converts geographical latitude and longitude to the nearest index on the dataset grid.'''\n",
    "        latitude_index = np.argmin(np.abs(latitude_array - latitude))\n",
    "        longitude_index = np.argmin(np.abs(longitude_array - longitude))\n",
    "        return latitude_index, longitude_index\n",
    "    \n",
    "    def convert_grid2coord(latitude_index, longitude_index):\n",
    "        '''Converts dataset grid indices back to geographical latitude and longitude coordinates.'''\n",
    "        latitude = latitude_array[latitude_index]\n",
    "        longitude = longitude_array[longitude_index]\n",
    "        return latitude, longitude\n",
    "    \n",
    "    def calculate_heuristic_cost(current_index, goal_index):\n",
    "        '''Estimates the cost from the current index to the goal using the Haversine formula as a heuristic.'''\n",
    "        current_latitude, current_longitude = convert_grid2coord(*current_index)\n",
    "        goal_latitude, goal_longitude = convert_grid2coord(*goal_index)\n",
    "        heuristic_cost = calculate_haversine_distance(current_longitude, current_latitude, goal_longitude, goal_latitude)\n",
    "        return heuristic_cost\n",
    "    \n",
    "    def calculate_movement_cost(model_dataset, current_index, next_index, speed):\n",
    "        '''Calculates the cost of moving from the current index to the next, taking into account the effect of ocean currents.'''\n",
    "        current_latitude, current_longitude = convert_grid2coord(*current_index)\n",
    "        next_latitude, next_longitude = convert_grid2coord(*next_index)\n",
    "        direction_to_next_index = np.arctan2(next_longitude - current_longitude, next_latitude - current_latitude)\n",
    "        u_current_component = model_dataset['u_depth_avg'].isel(lat=current_index[0], lon=current_index[1]).values\n",
    "        v_current_component = model_dataset['v_depth_avg'].isel(lat=current_index[0], lon=current_index[1]).values\n",
    "        glider_velocity_component_u = speed * np.cos(direction_to_next_index)\n",
    "        glider_velocity_component_v = speed * np.sin(direction_to_next_index)\n",
    "        net_velocity_component_u = glider_velocity_component_u + u_current_component\n",
    "        net_velocity_component_v = glider_velocity_component_v + v_current_component\n",
    "        net_speed = np.sqrt(net_velocity_component_u**2 + net_velocity_component_v**2)\n",
    "        net_speed = max(net_speed, 0.1)\n",
    "        distance_to_next_index = calculate_haversine_distance(current_longitude, current_latitude, next_longitude, next_latitude)\n",
    "        movement_cost = distance_to_next_index / net_speed\n",
    "        return movement_cost\n",
    "    \n",
    "    def generate_neighbor_nodes(index):\n",
    "        '''Generates neighboring index nodes for exploration based on the current index's position.'''\n",
    "        latitude_index, longitude_index = index\n",
    "        for delta_latitude in [-1, 0, 1]:\n",
    "            for delta_longitude in [-1, 0, 1]:\n",
    "                if delta_latitude == 0 and delta_longitude == 0:\n",
    "                    continue\n",
    "                new_latitude_index, new_longitude_index = latitude_index + delta_latitude, longitude_index + delta_longitude\n",
    "                if 0 <= new_latitude_index < len(latitude_array) and 0 <= new_longitude_index < len(longitude_array):\n",
    "                    yield (new_latitude_index, new_longitude_index)\n",
    "    \n",
    "    def reconstruct_path(came_from_dictionary, start_index, goal_index):\n",
    "        '''Reconstructs the path from the start index to the goal index using the came_from dictionary populated by the A* algorithm.'''\n",
    "        current_index = goal_index\n",
    "        optimal_path = [current_index]\n",
    "        while current_index != start_index:\n",
    "            current_index = came_from_dictionary[current_index]\n",
    "            optimal_path.append(current_index)\n",
    "        optimal_path.reverse()\n",
    "        optimal_path_coords = [convert_grid2coord(*index) for index in optimal_path]\n",
    "        return optimal_path_coords\n",
    "    \n",
    "    def algorithm_a_star(model_dataset, start_index, end_index, glider_raw_speed):\n",
    "        '''Executes the A* search algorithm to find the most efficient path from the start index to the goal index.'''\n",
    "        open_set = [(calculate_heuristic_cost(start_index, end_index), start_index)]\n",
    "        came_from = {start_index: None}\n",
    "        g_score = {start_index: 0}\n",
    "        f_score = {start_index: calculate_heuristic_cost(start_index, end_index)}\n",
    "        path_found = False\n",
    "        while open_set:\n",
    "            _, current = heapq.heappop(open_set)\n",
    "            if current == end_index:\n",
    "                path_found = True\n",
    "                break\n",
    "            for neighbor in generate_neighbor_nodes(current):\n",
    "                tentative_g_score = g_score[current] + calculate_movement_cost(model_dataset, current, neighbor, glider_raw_speed)\n",
    "                if tentative_g_score < g_score.get(neighbor, float('inf')):\n",
    "                    came_from[neighbor] = current\n",
    "                    g_score[neighbor] = tentative_g_score\n",
    "                    f_score[neighbor] = tentative_g_score + calculate_heuristic_cost(neighbor, end_index)\n",
    "                    if neighbor not in [n for _, n in open_set]:\n",
    "                        heapq.heappush(open_set, (f_score[neighbor], neighbor))\n",
    "        if path_found:\n",
    "            path = reconstruct_path(came_from, start_index, end_index)\n",
    "            time, distance = calculate_route_analytics(model_dataset, start_index, end_index, glider_raw_speed)\n",
    "        else:\n",
    "            print(f\"Direct path used from {convert_grid2coord(*start_index)} to {convert_grid2coord(*end_index)}.\")\n",
    "            path, time, distance = calculate_direct_path(start_index, end_index, glider_raw_speed)\n",
    "        return path, time, distance\n",
    "    \n",
    "    print(\"New Version\")\n",
    "\n",
    "    mission_waypoints = config['MISSION']['GPS_coords']\n",
    "    latitude_array = model_dataset['lat'].values\n",
    "    longitude_array = model_dataset['lon'].values\n",
    "    \n",
    "    optimal_mission_path = []\n",
    "    total_time = 0\n",
    "    total_distance = 0\n",
    "    \n",
    "    for i in range(len(mission_waypoints) - 1):\n",
    "        start_index = convert_coord2grid(*mission_waypoints[i])\n",
    "        end_index = convert_coord2grid(*mission_waypoints[i + 1])\n",
    "        segment_path, segment_time, segment_distance = algorithm_a_star(model_dataset, start_index, end_index, glider_raw_speed)\n",
    "        optimal_mission_path.extend(segment_path[:-1])\n",
    "        total_time += segment_time\n",
    "        total_distance += segment_distance\n",
    "    optimal_mission_path.append(mission_waypoints[-1])\n",
    "    \n",
    "    print(f\"Total mission time (adjusted): {total_time} seconds\")\n",
    "    print(f\"Total mission distance: [{total_distance}] meters\")\n",
    "\n",
    "    return optimal_mission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimal_path(ax, config, model_depth_average):\n",
    "\n",
    "    '''\n",
    "    Plots the optimal path for the mission between all successive waypoints given in the GPS_coords list.\n",
    "\n",
    "    Args:\n",
    "    - ax (matplotlib.axes.Axes): Matplotlib axes object.\n",
    "    - config (dict): Configuration dictionary.\n",
    "    - model_depth_average (xarray.Dataset): Depth-averaged ocean current dataset.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    '''\n",
    "\n",
    "    optimal_mission_path = compute_optimal_path(config, model_depth_average, glider_raw_speed=0.4)\n",
    "    route_lats, route_lons = zip(*optimal_mission_path)\n",
    "    \n",
    "    ax.plot(route_lons, route_lats, 'o-', transform=ccrs.PlateCarree(), markersize=5, linewidth=3, color='black', zorder=94)\n",
    "\n",
    "def GGS_plot_threshold(config, directory, datetime_index, model_datasets, latitude_qc=None, longitude_qc=None, density=2, mag1=0.0, mag2=0.2, mag3=0.3, mag4=0.4, mag5=0.5, gliders=None, show_waypoints=False, show_eez=False, show_qc=False, manual_extent=None, compute_optimal_path=False):\n",
    "    \n",
    "    '''\n",
    "    Plot the depth-averaged current fields from three datasets side by side.\n",
    "\n",
    "    Args:\n",
    "    - config (dict): Glider Guidance System mission configuration.\n",
    "    - directory (str): Directory to save the plot.\n",
    "    - datetime_index (int): Index of the datetime for the plot title.\n",
    "    - model_datasets (tuple): Tuple containing the model datasets.\n",
    "    - latitude_qc (float): Latitude for QC plotting.\n",
    "    - longitude_qc (float): Longitude for QC plotting.\n",
    "    - density (int): Density of the streamplot.\n",
    "    - mag1 (float): Threshold for the first magnitude level.\n",
    "    - mag2 (float): Threshold for the second magnitude level.\n",
    "    - mag3 (float): Threshold for the third magnitude level.\n",
    "    - mag4 (float): Threshold for the fourth magnitude level.\n",
    "    - mag5 (float): Threshold for the fifth magnitude level.\n",
    "    - gliders (optional): DataFrame containing glider data for plotting.\n",
    "    - show_waypoints (bool): Flag to show the glider waypoints.\n",
    "    - show_qc (bool): Flag to show the QC sample point.\n",
    "    - show_eez (bool): Flag to show the Exclusive Economic Zone (EEZ).\n",
    "    - manual_extent (list or None): Manual specification of plot extent.\n",
    "    - compute_optimal_path (bool): Flag to compute and plot the optimal path.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    '''\n",
    "\n",
    "    print(f\"\\n### CREATING THRESHOLD PLOT ###\\n\")\n",
    "    start_time = print_starttime()\n",
    "\n",
    "    valid_datasets = [datasets for datasets in model_datasets if datasets is not None]\n",
    "    num_datasets = len(valid_datasets)\n",
    "    if num_datasets == 0:\n",
    "        print(\"No datasets provided for plotting.\")\n",
    "        end_time = print_endtime()\n",
    "        print_runtime(start_time, end_time)\n",
    "        return\n",
    "\n",
    "    def plot_threshold(ax, config, model_depth_average, latitude_qc, longitude_qc, density, mag1, mag2, mag3, mag4, mag5, gliders, show_waypoints, show_qc, show_eez, manual_extent, compute_optimal_path):\n",
    "        \n",
    "        longitude = model_depth_average.lon.values.squeeze()\n",
    "        latitude = model_depth_average.lat.values.squeeze()\n",
    "        u_depth_avg = model_depth_average['u_depth_avg'].values.squeeze()\n",
    "        v_depth_avg = model_depth_average['v_depth_avg'].values.squeeze()\n",
    "        mag_depth_avg = model_depth_average['mag_depth_avg'].values.squeeze()\n",
    "        \n",
    "        if manual_extent is not None and len(manual_extent) == 2 and all(len(sublist) == 2 for sublist in manual_extent):\n",
    "            map_extent = [manual_extent[0][1], manual_extent[1][1], manual_extent[0][0], manual_extent[1][0]]\n",
    "        else:\n",
    "            data_extent_lon = [float(longitude.min()), float(longitude.max())]\n",
    "            data_extent_lat = [float(latitude.min()), float(latitude.max())]\n",
    "            map_extent = data_extent_lon + data_extent_lat\n",
    "        ax.set_extent(map_extent, crs=ccrs.PlateCarree())\n",
    "        plot_formatted_ticks(ax, map_extent[:2], map_extent[2:], proj=ccrs.PlateCarree(), fontsize=16, label_left=True, label_right=False, label_bottom=True, label_top=False, gridlines=True)\n",
    "\n",
    "        plot_threshold_zones(ax, longitude, latitude, mag_depth_avg, mag1, mag2, mag3, mag4, mag5, threshold_legend=True)\n",
    "        plot_streamlines(ax, longitude, latitude, u_depth_avg, v_depth_avg, density=density)\n",
    "\n",
    "        if gliders is not None:\n",
    "            plot_add_gliders(ax, gliders, legend=True)\n",
    "            glider_legend = ax.get_legend()\n",
    "            if glider_legend:\n",
    "                glider_legend.get_frame().set_alpha(0.5)\n",
    "                glider_legend.get_frame().set_facecolor('white')\n",
    "                ax.add_artist(glider_legend)\n",
    "\n",
    "        if show_waypoints:\n",
    "            plot_glider_route(ax, config)\n",
    "            \n",
    "        if compute_optimal_path:\n",
    "            plot_optimal_path(ax, config, model_depth_average)\n",
    "        \n",
    "        if show_qc:\n",
    "            (y_index, x_index), (lat_index, lon_index) = calculate_gridpoint(model_depth_average, latitude_qc, longitude_qc)\n",
    "            qc_lon = model_depth_average['lon'].isel(x=x_index, y=y_index).values\n",
    "            qc_lat = model_depth_average['lat'].isel(x=x_index, y=y_index).values\n",
    "            circle = Circle((qc_lon, qc_lat), radius=0.25, edgecolor='purple', facecolor='none', linewidth=2, transform=ccrs.PlateCarree(), zorder=95)\n",
    "            ax.add_patch(circle)\n",
    "\n",
    "        if show_eez:\n",
    "            plot_add_eez(ax, config, color='dimgrey', linewidth=3, zorder=90)\n",
    "        \n",
    "        try:\n",
    "            plot_bathymetry(ax, config, model_depth_average, isobath1=-100, isobath2=-1000, downsample=\"auto\", show_legend=False)\n",
    "            bathymetry_legend = ax.get_legend()\n",
    "            if bathymetry_legend:\n",
    "                bathymetry_legend.get_frame().set_alpha(0.5)\n",
    "                ax.add_artist(bathymetry_legend)\n",
    "        except:\n",
    "            print(f\"WARNING: Bathymetry contouring was unsuccessful for {model_depth_average.attrs['model_name']}. Using default ocean color instead.\")\n",
    "            ax.add_feature(cfeature.OCEAN, zorder=1)\n",
    "\n",
    "        ax.add_feature(cfeature.GSHHSFeature(scale='full'), edgecolor=\"black\", facecolor=\"tan\", linewidth=0.25, zorder=90)\n",
    "        ax.add_feature(cfeature.RIVERS, edgecolor=\"steelblue\", linewidth=0.25, zorder=90)\n",
    "        ax.add_feature(cfeature.LAKES, edgecolor=\"black\", facecolor=\"lightsteelblue\", linewidth=0.25, zorder=90)\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor=\"black\", linewidth=0.25, zorder=90)\n",
    "        \n",
    "    fig, axs = plt.subplots(1, num_datasets, subplot_kw={'projection': ccrs.Mercator()}, figsize=(10*num_datasets, 10))\n",
    "    if num_datasets == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    model_names = []\n",
    "    for ax, (model_data, depth_average_data, bin_average_data) in zip(axs, valid_datasets):\n",
    "        model_name = depth_average_data.attrs['model_name']\n",
    "        model_names.append(model_name)\n",
    "        plot_threshold(ax, config, depth_average_data, latitude_qc, longitude_qc, density, mag1, mag2, mag3, mag4, mag5, gliders, show_waypoints, show_qc, show_eez, manual_extent, compute_optimal_path)\n",
    "        ax.set_title(f\"{model_name}\", fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    title_text = f\"Depth Averaged Current Threshold Zones - Depth Range: {config['MISSION']['max_depth']}m\"\n",
    "    model_names_combined = \" vs. \".join(model_names)\n",
    "    format_figure_titles(axs[0], fig, config, datetime_index, model_name=model_names_combined, title=title_text)\n",
    "\n",
    "    file_datetime = format_save_datetime(datetime_index)\n",
    "    fig_filename = f\"DepthAverageThreshold_{config['MISSION']['max_depth']}m_{file_datetime}.png\"\n",
    "    fig_path = os.path.join(directory, fig_filename)\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    end_time = print_endtime()\n",
    "    print_runtime(start_time, end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CREATING THRESHOLD PLOT ###\n",
      "\n",
      "Start time (UTC): 2024-04-11 20:27:43.202873\n",
      "Computing optimal path for the mission.\n",
      "!!!WARNING!!!: This feature is experimental and may not work as expected. Use at your own risk.\n",
      "New Version\n",
      "Direct path used from (41.66667, -70.5) to (40.0, -70.666664).\n",
      "Total mission time (adjusted): [17688631.84835901] seconds\n",
      "Total mission distance: [6098654.257977845] meters\n",
      "End time (UTC): 2024-04-11 20:32:33.568124\n",
      "Run time: 0:04:50.365251\n"
     ]
    }
   ],
   "source": [
    "GGS_plot_threshold(\n",
    "        config_flag,\n",
    "        sub_directory_plots,\n",
    "        datetime_index,\n",
    "        model_datasets,\n",
    "        latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "        density=density_flag,\n",
    "        mag1=mag1_flag, mag2=mag2_flag, mag3=mag3_flag, mag4=mag4_flag, mag5=mag5_flag,\n",
    "        gliders=glider_data_flag,\n",
    "        show_waypoints=show_waypoints_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "        manual_extent=manual_extent_flag,\n",
    "        compute_optimal_path=compute_optimal_path_flag\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17688631\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ggs0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
