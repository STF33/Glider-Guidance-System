{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find header.dxf (GDAL_DATA is not defined)\n",
      "c:\\Users\\sal_f\\anaconda3\\envs\\env_ggs0\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "\n",
    "from X_functions import *\n",
    "from X_config import *\n",
    "from X_models import *\n",
    "from X_interpolation import *\n",
    "from X_plots import *\n",
    "\n",
    "from GGS_main import *\n",
    "\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GGS Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "power=1\n",
    "path=\"local\"\n",
    "config_name=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### IMPORTING GGS CONFIGURATION: test ###\n",
      "\n",
      "Configuration import success!\n",
      "\n",
      "### PROCESSING GGS CONFIGURATION ###\n",
      "\n",
      "Configuration:\n",
      "\n",
      "--> MISSION\n",
      "mission_name: TEST\n",
      "target_date: 2024-04-07T15:19:24+0000\n",
      "max_depth: 1000\n",
      "extent: ((-40, 0), (-20, 22))\n",
      "GPS_coords: [[15.067, -23.65], [-33.907, 18.564]]\n",
      "glider_id: None\n",
      "\n",
      "--> MODEL\n",
      "single_datetime: True\n",
      "enable_rtofs: False\n",
      "enable_cmems: True\n",
      "enable_gofs: True\n",
      "save_model_data: False\n",
      "save_depth_average: True\n",
      "save_bin_average: False\n",
      "chunk: True\n",
      "\n",
      "--> PLOT\n",
      "latitude_qc: -6\n",
      "longitude_qc: 0\n",
      "density: 3\n",
      "mag1: 0.0\n",
      "mag2: 0.2\n",
      "mag3: 0.3\n",
      "mag4: 0.4\n",
      "mag5: 0.5\n",
      "tolerance: 7.5\n",
      "show_gliders: False\n",
      "show_route: True\n",
      "show_eez: True\n",
      "show_qc: False\n",
      "manual_extent: None\n",
      "\n",
      "--> DATA\n",
      "bathymetry_path: c:\\Users\\sal_f\\OneDrive\\Desktop\\STF-0\\!-GGS\\GGS_Scripts\\data/bathymetry/GEBCO_2023_sub_ice_topo.nc\n",
      "eez_path: c:\\Users\\sal_f\\OneDrive\\Desktop\\STF-0\\!-GGS\\GGS_Scripts\\data/eez/eez_boundaries_v12.shp\n",
      "\n",
      "--> ADVANCED\n",
      "reprocess: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config_name is None:\n",
    "    print(\"No config file specified. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "config = GGS_config_import(config_name)\n",
    "\n",
    "target_datetime = config['MISSION'].get('target_date')\n",
    "if not target_datetime:\n",
    "    print(\"Issue with target datetime. Using current datetime.\")\n",
    "    target_datetime = dt.datetime.now(dt.timezone.utc)\n",
    "\n",
    "if path == \"local\":\n",
    "    root_directory = GGS_config_process(config, path=\"default\")\n",
    "elif path == \"rucool\":\n",
    "    root_directory = GGS_config_process(config, path=\"/www/web/rucool/hurricane/model_comparisons/maps/yucatan\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid root directory.\")\n",
    "\n",
    "datetime_list = [target_datetime.replace(hour=0, minute=0, second=0, microsecond=0).strftime('%Y-%m-%dT%H:%M:%SZ')]\n",
    "datetime_index = datetime_list[0]\n",
    "\n",
    "glider_dataframes = None\n",
    "if config['PLOT'].get('show_gliders'):\n",
    "    min_lat, min_lon = config['MISSION']['extent'][0]\n",
    "    max_lat, max_lon = config['MISSION']['extent'][1]\n",
    "    search_extent = [min_lon, max_lon, min_lat, max_lat]\n",
    "    glider_dataframes = acquire_gliders(\n",
    "        extent=search_extent,\n",
    "        target_date=target_datetime,\n",
    "        date_delta=dt.timedelta(days=1),\n",
    "        requested_variables=[\"time\", \"longitude\", \"latitude\", \"profile_id\", \"depth\"],\n",
    "        print_vars=False,\n",
    "        target=\"all\",\n",
    "        request_timeout=5,\n",
    "        enable_parallel=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime 2024-04-07T00:00:00Z unprocessed, proceeding with task.\n"
     ]
    }
   ],
   "source": [
    "datetime_index = datetime_index\n",
    "config_flag = config\n",
    "root_directory_flag = root_directory\n",
    "glider_data_flag = glider_dataframes\n",
    "\n",
    "enable_rtofs_flag = config_flag['MODEL']['enable_rtofs']\n",
    "enable_cmems_flag = config_flag['MODEL']['enable_cmems']\n",
    "enable_gofs_flag = config_flag['MODEL']['enable_gofs']\n",
    "save_model_data_flag = config_flag['MODEL']['save_model_data']\n",
    "save_depth_average_flag = config_flag['MODEL']['save_depth_average']\n",
    "save_bin_average_flag = config_flag['MODEL']['save_bin_average']\n",
    "chunk_flag = config_flag['MODEL']['chunk']\n",
    "\n",
    "latitude_qc_flag = config_flag['PLOT']['latitude_qc']\n",
    "longitude_qc_flag = config_flag['PLOT']['longitude_qc']\n",
    "density_flag = config_flag['PLOT']['density']\n",
    "mag1_flag = config_flag['PLOT']['mag1']\n",
    "mag2_flag = config_flag['PLOT']['mag2']\n",
    "mag3_flag = config_flag['PLOT']['mag3']\n",
    "mag4_flag = config_flag['PLOT']['mag4']\n",
    "mag5_flag = config_flag['PLOT']['mag5']\n",
    "tolerance_flag = config_flag['PLOT']['tolerance']\n",
    "show_route_flag = config_flag['PLOT']['show_route']\n",
    "show_eez_flag = config_flag['PLOT']['show_eez']\n",
    "show_qc_flag = config_flag['PLOT']['show_qc']\n",
    "manual_extent_flag = config_flag['PLOT']['manual_extent']\n",
    "\n",
    "sub_directory_plots = os.path.join(root_directory_flag, \"plots\", ''.join(datetime_index[:10].split('-')))\n",
    "os.makedirs(sub_directory_plots, exist_ok=True)\n",
    "sub_directory_data = os.path.join(root_directory_flag, \"data\", ''.join(datetime_index[:10].split('-')))\n",
    "os.makedirs(sub_directory_data, exist_ok=True)\n",
    "\n",
    "check_datetime = pd.to_datetime(datetime_index).strftime('%Y%m%dT%HZ')\n",
    "check_pattern = os.path.join(sub_directory_data, f\"*_DepthAverageData_{check_datetime}.nc\")\n",
    "check_files = glob.glob(check_pattern)\n",
    "if check_files:\n",
    "    print(f\"Datetime {datetime_index} already processed: {check_files[0]}, skipping task.\")\n",
    "else:\n",
    "    print(f\"Datetime {datetime_index} unprocessed, proceeding with task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MODEL DATA: [CMEMS] ###\n",
      "\n",
      "INFO - 2024-04-07T15:19:28Z - Dataset version was not specified, the latest one was selected: \"202211\"\n",
      "INFO - 2024-04-07T15:19:28Z - Dataset part was not specified, the first one was selected: \"default\"\n",
      "INFO - 2024-04-07T15:19:30Z - Service was not specified, the default one was selected: \"arco-geo-series\"\n",
      "\n",
      "### INTERPOLATING CMEMS MODEL DATA ###\n",
      "\n",
      "Start time (UTC): 2024-04-07 15:19:33.340688\n",
      "End time (UTC): 2024-04-07 15:20:04.592568\n",
      "Run time: 0:00:31.251880\n",
      "\n",
      "### MODEL DATA: [GOFS] ###\n",
      "\n",
      "\n",
      "### INTERPOLATING GOFS MODEL DATA ###\n",
      "\n",
      "Start time (UTC): 2024-04-07 15:20:05.620961\n",
      "End time (UTC): 2024-04-07 15:21:37.327145\n",
      "Run time: 0:01:31.706184\n"
     ]
    }
   ],
   "source": [
    "model_datasets = []\n",
    "    \n",
    "if enable_rtofs_flag:\n",
    "    try:\n",
    "        rtofs = RTOFS()\n",
    "        rtofs.rtofs_load(config_flag, datetime_index)\n",
    "        rtofs.rtofs_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "        rtofs_model_data = rtofs.data\n",
    "        \n",
    "        rtofs_depth_average, rtofs_bin_average = interpolate_rtofs(config_flag, sub_directory_data, rtofs_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "\n",
    "        rtofs_datasets = (rtofs_model_data, rtofs_depth_average, rtofs_bin_average)\n",
    "        model_datasets.append(rtofs_datasets)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during RTOFS processing: {e}\")\n",
    "\n",
    "if enable_cmems_flag:\n",
    "    try:\n",
    "        cmems = CMEMS(username='sfricano1', password='GlobalGliders1')\n",
    "        cmems.cmems_load(config_flag, datetime_index)\n",
    "        cmems.cmems_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "        cmems_model_data = cmems.data\n",
    "        \n",
    "        cmems_depth_average, cmems_bin_average = interpolate_cmems(config_flag, sub_directory_data, cmems_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "        \n",
    "        cmems_datasets = (cmems_model_data, cmems_depth_average, cmems_bin_average)\n",
    "        model_datasets.append(cmems_datasets)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during CMEMS processing: {e}\")\n",
    "\n",
    "if enable_gofs_flag:\n",
    "    try:\n",
    "        gofs = GOFS()\n",
    "        gofs.gofs_load(config_flag, datetime_index)\n",
    "        gofs.gofs_save(config_flag, sub_directory_data, save_data=save_model_data_flag)\n",
    "        gofs_model_data = gofs.data\n",
    "\n",
    "        gofs_depth_average, gofs_bin_average = interpolate_gofs(config_flag, sub_directory_data, gofs_model_data, chunk=chunk_flag, save_depth_average=save_depth_average_flag, save_bin_average=save_bin_average_flag)\n",
    "\n",
    "        gofs_datasets = (gofs_model_data, gofs_depth_average, gofs_bin_average)\n",
    "        model_datasets.append(gofs_datasets)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GOFS processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GGS_plot_magnitude(\n",
    "    config_flag,\n",
    "    sub_directory_plots,\n",
    "    datetime_index,\n",
    "    model_datasets,\n",
    "    latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "    density=density_flag,\n",
    "    gliders=glider_data_flag,\n",
    "    show_route=show_route_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "    manual_extent=manual_extent_flag\n",
    ")\n",
    "GGS_plot_threshold(\n",
    "    config_flag,\n",
    "    sub_directory_plots,\n",
    "    datetime_index,\n",
    "    model_datasets,\n",
    "    latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "    density=density_flag,\n",
    "    mag1=mag1_flag, mag2=mag2_flag, mag3=mag3_flag, mag4=mag4_flag, mag5=mag5_flag,\n",
    "    gliders=glider_data_flag,\n",
    "    show_route=show_route_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "    manual_extent=manual_extent_flag\n",
    ")\n",
    "GGS_plot_advantage(\n",
    "    config_flag,\n",
    "    sub_directory_plots,\n",
    "    datetime_index,\n",
    "    model_datasets,\n",
    "    latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "    density=density_flag,\n",
    "    tolerance=tolerance_flag,\n",
    "    mag1=mag1_flag, mag2=mag2_flag, mag3=mag3_flag, mag4=mag4_flag, mag5=mag5_flag,\n",
    "    gliders=glider_data_flag,\n",
    "    show_route=show_route_flag, show_eez=show_eez_flag, show_qc=show_qc_flag,\n",
    "    manual_extent=manual_extent_flag\n",
    ")\n",
    "GGS_plot_profiles(\n",
    "    config_flag,\n",
    "    sub_directory_plots,\n",
    "    datetime_index,\n",
    "    model_datasets,\n",
    "    latitude_qc=latitude_qc_flag, longitude_qc=longitude_qc_flag,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GGS Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmems_depth_average = xr.open_dataset(\"C:/Users/sal_f/OneDrive/Desktop/STF-0/!-GGS/GGS_Scripts/data/reprocess/Sentinel Leg 2_CMEMS_DepthAverage_20240328T00Z.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CREATING GEODATAFRAME FILES ###\n",
      "\n",
      "Start time (UTC): 2024-04-07 15:46:46.752521\n",
      "End time (UTC): 2024-04-07 15:47:02.861882\n",
      "Run time: 0:00:16.109361\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def GGS_export_gpkg(directory, datetime_index, model_datasets):\n",
    "    \n",
    "    '''\n",
    "    Process and export data from model datasets to CSV and GeoPackage files.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Directory to save the files.\n",
    "    - datetime_index (str): Datetime index for the model datasets.\n",
    "    - model_datasets (tuple): Tuple containing the model datasets.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    '''\n",
    "\n",
    "    print(f\"\\n### CREATING GEODATAFRAME FILES ###\\n\")\n",
    "    start_time = print_starttime()\n",
    "\n",
    "    valid_datasets = [datasets for datasets in model_datasets if datasets is not None]\n",
    "    num_datasets = len(valid_datasets)\n",
    "    if num_datasets == 0:\n",
    "        print(\"No datasets provided for GeoDataFrame conversion.\")\n",
    "        end_time = print_endtime()\n",
    "        print_runtime(start_time, end_time)\n",
    "        return\n",
    "\n",
    "    file_datetime = format_save_datetime(datetime_index)\n",
    "    for model_data, depth_average_data, bin_average_data in valid_datasets:\n",
    "        model_name = depth_average_data.attrs['model_name']\n",
    "        csv_file = f\"{model_name}_depth_average_{file_datetime}.csv\"\n",
    "        csv_path = os.path.join(directory, csv_file)\n",
    "        gpkg_file = f\"{model_name}_depth_average_{file_datetime}.gpkg\"\n",
    "        gpkg_path = os.path.join(directory, gpkg_file)\n",
    "\n",
    "        dataframe = depth_average_data.to_dataframe().reset_index()\n",
    "        dataframe = dataframe[['lat', 'lon', 'mag_depth_avg', 'dir_depth_avg']]\n",
    "        dataframe.dropna(subset=['mag_depth_avg', 'dir_depth_avg'], inplace=True)\n",
    "        dataframe.to_csv(csv_path, index=False)\n",
    "\n",
    "        geometry = [Point(xy) for xy in zip(dataframe['lon'], dataframe['lat'])]\n",
    "        geodataframe = gpd.GeoDataFrame(dataframe, geometry=geometry)\n",
    "        geodataframe.crs = \"EPSG:4326\"\n",
    "        geodataframe.to_file(gpkg_path, driver=\"GPKG\")\n",
    "\n",
    "    end_time = print_endtime()\n",
    "    print_runtime(start_time, end_time)\n",
    "\n",
    "GGS_export_gpkg(config, sub_directory_data, model_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ggs0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
